{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96852a5d-4033-455a-8d80-cbfda2ceafac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab34c69-975d-482d-a88f-a3bf1421fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminability(H):\n",
    "    return 1 - 1/2**H\n",
    "\n",
    "def ent(D):\n",
    "    if D == 1: return 0\n",
    "    return np.log2(1/(1-D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15096ca4-78fe-4fd4-b465-90c89c0c2016",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGS = ['ar', 'ca', 'de', 'en', 'es', 'fr', 'he', 'it', 'nl', 'pl', 'sl', 'sv']\n",
    "labels = ['arabic', 'catalan', 'german', 'english', 'spanish', 'french', 'hebrew', 'italian', 'dutch', 'polish', 'slovenian', 'swedish']\n",
    "num_values = [6, 4, 4, 2, 4, 4, 6, 4, 3, 6, 9, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab3586-86bd-438f-bcea-4a0f8cc6065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for all languages\n",
    "langs = {}\n",
    "for lang in LANGS:\n",
    "    summary_df = pd.read_csv(f'../distributions/{lang}_dist_summary.csv')\n",
    "    if lang != 'nl':\n",
    "        summary_df = summary_df.rename(columns={'Unnamed: 0': 'category'})\n",
    "    if lang == 'nl':\n",
    "        summary_df = summary_df.drop(columns=['Unnamed: 0'])\n",
    "    langs[lang] = summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fdb276-54f5-4d2f-a06d-87facc56918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.gridspec as gridspec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fffdcd-3f63-45bd-a586-60e161b5338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the x values\n",
    "x = np.arange(1, 11)  # Start from 1 to avoid log2(0)\n",
    "\n",
    "# Compute entropy (log2(x)) and discriminability\n",
    "max_ent = np.log2(np.arange(1, 11, 0.2))\n",
    "max_discrim = discriminability(max_ent)\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, ax1 = plt.subplots(figsize=(9, 6.5))\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[10, 0.5], wspace=0.3)  # Adjust wspace to increase space\n",
    "\n",
    "ax1 = plt.subplot(gs[0])  # Main plot\n",
    "cax = plt.subplot(gs[1])  # Colorbar axis\n",
    "\n",
    "# Plot the log2(x) curve\n",
    "ax1.plot(np.arange(1, 11, 0.2), max_discrim, label='max (uniform)', alpha=0.6)\n",
    "\n",
    "# Plot points\n",
    "token_entropies = np.array([float(langs[lang][langs[lang]['category']=='token']['Entropy']) for lang in LANGS])\n",
    "token_cs = np.log2(num_values) - token_entropies\n",
    "\n",
    "anim_token_entropies = np.array([float(langs[lang][langs[lang]['category']=='anim_token']['Entropy']) for lang in LANGS])\n",
    "anim_token_cs = np.log2(num_values) - anim_token_entropies\n",
    "\n",
    "vmin=0\n",
    "vmax=max(max(token_cs), max(anim_token_cs))\n",
    "\n",
    "cb = ax1.scatter(num_values, discriminability(token_entropies), marker='o', c=token_cs, label='all nouns', vmin=vmin, vmax=vmax)\n",
    "scatter=ax1.scatter(num_values, discriminability(anim_token_entropies), marker='^', c=anim_token_cs, label='animate nouns', norm=cb.norm)\n",
    "\n",
    "# Label each point\n",
    "for i, lang in enumerate(LANGS):\n",
    "    if lang in ('en', 'nl', 'sl'):\n",
    "        ax1.annotate(f'{labels[i]}', (num_values[i], discriminability(token_entropies[i])), textcoords=\"offset points\", \n",
    "                 xytext=(-5, -2), ha='right', fontsize=9, \n",
    "                )\n",
    "        ax1.annotate(f'{labels[i]}', (num_values[i], discriminability(anim_token_entropies[i])), textcoords=\"offset points\", \n",
    "                 xytext=(-5, -2), ha='right', fontsize=9,)\n",
    "    elif lang in ('ar', 'es'):\n",
    "        ax1.annotate(f'{labels[i]}', (num_values[i], discriminability(token_entropies[i])), textcoords=\"offset points\", \n",
    "                 xytext=(5, -2), ha='left', fontsize=9,\n",
    "                )\n",
    "        ax1.annotate(f'{labels[i]}', (num_values[i], discriminability(anim_token_entropies[i])), textcoords=\"offset points\", \n",
    "                 xytext=(5, -2), ha='left', fontsize=9, )\n",
    "    elif lang == 'de':\n",
    "        ax1.annotate(f'{labels[i]}', (num_values[i], discriminability(token_entropies[i])), textcoords=\"offset points\", \n",
    "                 xytext=(0, 20), ha='center', fontsize=9, arrowprops=dict(arrowstyle='-', color='black', lw=1)\n",
    "                )\n",
    "        ax1.annotate(f'{labels[i]}', (num_values[i], discriminability(anim_token_entropies[i])), textcoords=\"offset points\", \n",
    "                 xytext=(5, -2), ha='left', fontsize=9, )\n",
    "    elif lang == 'ca':\n",
    "        ax1.annotate(f'{labels[i]}', (num_values[i], discriminability(token_entropies[i])), textcoords=\"offset points\", \n",
    "                 xytext=(-30, 10), ha='right', fontsize=9, arrowprops=dict(arrowstyle='-', color='black', lw=1)\n",
    "                )\n",
    "        ax1.annotate(f'{labels[i]}', (num_values[i], discriminability(anim_token_entropies[i])), textcoords=\"offset points\", \n",
    "                 xytext=(-50, -2), ha='right', fontsize=9, arrowprops=dict(arrowstyle='-', color='black', lw=1))\n",
    "    elif lang == 'it':\n",
    "        ax1.annotate(f'{labels[i]}', (num_values[i], discriminability(token_entropies[i])), textcoords=\"offset points\", \n",
    "                 xytext=(-40, 5), ha='right', fontsize=9, arrowprops=dict(arrowstyle='-', color='black', lw=1)\n",
    "                )\n",
    "        ax1.annotate(f'{labels[i]}', (num_values[i], discriminability(anim_token_entropies[i])), textcoords=\"offset points\", \n",
    "                 xytext=(14, -20), ha='left', fontsize=9, arrowprops=dict(arrowstyle='-', color='black', lw=1))\n",
    "    elif lang == 'fr':\n",
    "        ax1.annotate(f'{labels[i]}', (num_values[i], discriminability(token_entropies[i])), textcoords=\"offset points\", \n",
    "                 xytext=(-45, -2), ha='right', fontsize=9, arrowprops=dict(arrowstyle='-', color='black', lw=1)\n",
    "                )\n",
    "        ax1.annotate(f'{labels[i]}', (num_values[i], discriminability(anim_token_entropies[i])), textcoords=\"offset points\", \n",
    "                 xytext=(-5, -2), ha='right', fontsize=9)\n",
    "    else:\n",
    "        ax1.annotate(f'{labels[i]}', (num_values[i], discriminability(token_entropies[i])), textcoords=\"offset points\", \n",
    "                     xytext=(-5, -2), ha='right', fontsize=9, \n",
    "                    )\n",
    "        ax1.annotate(f'{labels[i]}', (num_values[i], discriminability(anim_token_entropies[i])), textcoords=\"offset points\", \n",
    "                     xytext=(-5, -2), ha='right', fontsize=9,)\n",
    "\n",
    "\n",
    "# Set labels and title for the left y-axis and x-axis\n",
    "ax1.set_xlabel('Grammatical values', fontsize=15)\n",
    "ax1.set_ylabel('Discriminability', fontsize=15)\n",
    "ax1.set_ylim([0, 1.0])\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "ax1.set_xticks(np.arange(1, 11))\n",
    "\n",
    "# Create a second y-axis for discriminability\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Entropy (bits)', color='gray', rotation=270, labelpad=13, fontsize=15)\n",
    "ax2.tick_params(axis='y', labelcolor='gray')\n",
    "ax2.set_yticks(np.arange(0, 1.1, 0.2))\n",
    "e = [f'{ent(d):.2f}' for d in np.arange(0, 1.1, 0.2)]\n",
    "e[-1] = r'$\\infty$'\n",
    "ax2.set_yticklabels(e)\n",
    "ax2.set_ylim([0, 1.0])\n",
    "\n",
    "# Add legends\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.set_xlim([1, 10])\n",
    "\n",
    "# Add diagonal shading above the curve\n",
    "ax1.fill_between(np.arange(1, 11, 0.2), max_discrim, y2=max(max_discrim) + 1, \n",
    "                 interpolate=True, color='gray', alpha=0.2, hatch='//')\n",
    "\n",
    "ax1.tick_params(axis='both', which='major', labelsize=14)  # Increase size of major tick labels\n",
    "ax2.tick_params(axis='y', which='major', labelsize=14)\n",
    "\n",
    "# Add a color bar to the plot with specified limits\n",
    "cbar = plt.colorbar(scatter, cax=cax)\n",
    "cbar.set_label('KL-divergence from uniform (bits)', rotation=270, labelpad=13, fontsize=13, color='gray')\n",
    "\n",
    "# Show the plot\n",
    "plt.title('Grammatical systems: discriminability', fontsize=15)\n",
    "ax1.grid(zorder=0)\n",
    "ax1.xaxis.grid(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fba00b7-3ea6-439a-bb83-76fefd8d0aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
